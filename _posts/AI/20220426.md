---
title: "What is Machine Learning"
date: 2022-05-08
layout: posts
tags: AI
---

### 머신러닝이란
기계가 일일이 코드로 명시하지 않은 동작을 데이터로부터 학습하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야


### 머신러닝 알고리즘 종류
1. 지도학습: 정답이 있는 문제를 풀 경우
    - 회귀 Regression
        - 정답이 연속형 변수일 경우
    - 분류 Classification
        - 정답이 비연속형(범주형)일 경우
2. 비지도학습: 정답이 없는 문제를 풀 경우
    - 군집분석 Clustering
        - 주어진 데이터가 어떻게 구성되었는지 알아내려는 분석 방법
    - 강화학습 Reinforcement Learning
        - 행동에 따른 보상을 최대화 시키는 학습 방법


### 모델 선택
모델이란, 어떤 X가 주어졌을 때 f라는 함수를 통해 Y값을 도출하는 과정에서 f를 말함 (f(x) = aX + b)

1. 회귀모델
    - 선형 회귀
        - H(x) = Wx + b
        - 평균을 사용하여 최적의 기울기 W와 b의 값을 탐색
        - W 계수: 회귀선의 기울기로, x가 1증가할 때 예측값이 증가하는 정도
        - b 편향: 그래프에서 회귀선의 위치로, x=0일 때의 예측값
    
        ※ Mean Squared Error: 오차 제곱의 평균 구하기
        <pre>
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import mean_squared_error
        import pandas as pd
    
        df = pd.read_csv("./height.csv")
        X = df["height"]
        Y = df["weight"]
    
        line_fitter = LinearRegression()
        line_fitter.fit(X.values.reshape(-1,1), Y) # 모델 학습시키기 .fit(data, answer)
        line_fitter.coef_ # coefficient. 값이 클 수록 영향도가 높음
        
        predict = line_fitter.predict(X.values.reshape(-1,1)) # 예측하기
        MSE = mean_squared_error(y,predict)
        </pre>
    - 다중 선형 회귀
        - H(x1, x2, x3) = W1x1 + W2x2 + W3x3 + b (행렬로 표시)
        - 여러 개의 독립변수로 결과값을 예측하기 위한 방법

        <pre>
        from sklearn.model_selection import train_test_split
        import pandas as pd
        
        df = pd.read_csv("manhattan.csv")
        x = df[['bedrooms', 'bathrooms', 'size_sqft', 'min_to_subway', 'floor', 'building_age_yrs', 'no_fee', 'has_roofdeck', 
                'has_washer_dryer', 'has_doorman', 'has_elevator', 'has_dishwasher', 'has_patio', 'has_gym']]
        y = df[['rent']]

        # 데이터 나누기 작업
        # train_test_split (데이터, 정답, 나누는 비율, 셔플)
        # 나누는 비율은 학습/테스트 : 70%/30%, 80%/20%
        # 셔플 (데이터의 섞는 유무)
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)
        
        # LinearRegression함수를 통해 선형 회귀를 위한 정보들을 입력합니다.
        # fit_intercept는 선형회귀를 통해 얻는 모델에 상수항 (y절편)을 포함할 것인지 말지를 의미합니다.
        # n_jobs는 모델의 계산에 사용할 작업의 갯수를 의미합니다. -1이면 현 PC의 최대성능
        # normalize는 정규화 과정을 거친 데이터를 사용할 것인지를 의미합니다.
        mlr = LinearRegression(fit_intercept=False, n_jobs=-1, normalize=True)
        mlr.fit(x_train, y_train)
        
        # 학습된 모델의 성능을 평가합니다.
        # MSE는 오차의 제곱의 평균을 계산한 값입니다. 즉 값이 작을수록 실제 값과의 차이가 적음을 의미합니다.
        # predict()함수를 사용하여 예측을 진행합니다.
        predict = mlr.predict(x_test)
        MSE = mean_squared_error(y_test, predict)
        </pre>
    - 다항식 회귀

### 최적화 알고리즘
1. Bisection 
2. 경사 하강법 Gradient descent
    - 함수의 기울기(경사)를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜 극값에 이를 때까지 반복
    - 기울기(W)가 1에 수렴하는지 확인
    <pre>
    
    
    </pre>
